<p align="center">
  <img src="https://img.shields.io/badge/ğŸ·ï¸-Retail_Price_Predictor-blue?style=for-the-badge" alt="Project Title"/>
</p>

<h1 align="center">Retail Price Predictor</h1>

<p align="center">
  <em>From Classical ML to Genrative AI to Agentic AI â€” A Full-Stack Approach to Retail Price Estimation</em>
</p>

<p align="center">
  <img src="https://img.shields.io/badge/Python-3.11+-3776AB?style=flat-square&logo=python&logoColor=white" alt="Python"/>
  <img src="https://img.shields.io/badge/Jupyter-Notebook-F37626?style=flat-square&logo=jupyter&logoColor=white" alt="Jupyter"/>
  <img src="https://img.shields.io/badge/scikit--learn-F7931E?style=flat-square&logo=scikit-learn&logoColor=white" alt="scikit-learn"/>
  <img src="https://img.shields.io/badge/XGBoost-189FDD?style=flat-square&logo=xgboost&logoColor=white" alt="XGBoost"/>
  <img src="https://img.shields.io/badge/HuggingFace-FFD21E?style=flat-square&logo=huggingface&logoColor=black" alt="Hugging Face"/>
  <img src="https://img.shields.io/badge/OpenAI-412991?style=flat-square&logo=openai&logoColor=white" alt="OpenAI"/>
  <img src="https://img.shields.io/badge/Meta_Llama_3.2-0467DF?style=flat-square&logo=meta&logoColor=white" alt="Llama"/>
  <img src="https://img.shields.io/badge/LangChain-1C3C3C?style=flat-square&logo=langchain&logoColor=white" alt="LangChain"/>
  <img src="https://img.shields.io/badge/ChromaDB-FF6F61?style=flat-square&logo=googlechrome&logoColor=white" alt="Chroma"/>
  <img src="https://img.shields.io/badge/Gradio-F97316?style=flat-square&logo=gradio&logoColor=white" alt="Gradio"/>
  <img src="https://img.shields.io/badge/Modal-000000?style=flat-square&logo=modal&logoColor=white" alt="Modal"/>
</p>

<p align="center">
  <img src="https://img.shields.io/github/last-commit/emsikes/ml-retail-price-predictor?style=flat-square" alt="Last Commit"/>
  <img src="https://img.shields.io/github/languages/top/emsikes/ml-retail-price-predictor?style=flat-square" alt="Top Language"/>
  <img src="https://img.shields.io/badge/License-MIT-green?style=flat-square" alt="License"/>
</p>

---

## ğŸ“Œ Overview

**ML Retail Price Predictor** is an end-to-end machine learning project that tackles retail product price estimation through a progressive, multi-phase approach. Starting with classical ML baselines and advancing through NLP-enhanced models, supervised fine-tuning of frontier LLMs, and culminating in a production-grade **Agentic AI serverless application**, the project demonstrates the full spectrum of modern ML/AI engineering.

The pipeline ingests the **Amazon product dataset from Hugging Face**, explores and curates the data for price prediction, benchmarks traditional ML techniques, then pushes into LLM fine-tuning and retrieval-augmented generation (RAG) to build a multi-modal intelligent pricing assistant.

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        DATA LAYER                                   â”‚
â”‚  Hugging Face (Amazon Retail Dataset) â†’ Curation â†’ Preprocessing    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â–¼                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   CLASSICAL ML PIPELINE  â”‚   â”‚       LLM FINE-TUNING PIPELINE      â”‚
â”‚                          â”‚   â”‚                                      â”‚
â”‚  â€¢ Random Baseline       â”‚   â”‚  â€¢ OpenAI GPT-4o-mini (LoRA / SFT)  â”‚
â”‚  â€¢ Constant Baseline     â”‚   â”‚  â€¢ Meta Llama 3.2 (Fine-Tune)       â”‚
â”‚  â€¢ Linear Regression     â”‚   â”‚                                      â”‚
â”‚  â€¢ BoW + Linear Reg.     â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚  â€¢ Random Forest         â”‚                  â”‚
â”‚  â€¢ XGBoost               â”‚                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
               â”‚                              â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              AGENTIC AI APPLICATION LAYER                           â”‚
â”‚                                                                     â”‚
â”‚  LangChain (Orchestration) + ChromaDB (Vector Store)                â”‚
â”‚  Gradio (UI) + Modal.com (Serverless Compute)                       â”‚
â”‚                                                                     â”‚
â”‚  â†’ Multi-Modal RAG  â†’  Agentic Pricing Assistant                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š Model Benchmark Results

All models were evaluated on the Amazon retail product dataset with Mean Absolute Error (MAE), Mean Squared Error (MSE), and RÂ² score. Confidence intervals are reported at the 95% level.

| Model | MAE (Â± 95% CI) | MSE | RÂ² Score |
|:------|:----------------|:----|:---------|
| ğŸ² Random Pricer | 382.08 Â± 37.47 | 219,084 | -896.9% |
| ğŸ“ Constant Pricer | 106.18 Â± 14.36 | 106.18 | -0.2% |
| ğŸ“ˆ Linear Regression | 101.56 Â± 14.21 | 20,832 | 5.2% |
| ğŸ“ NLP Linear Regression (BoW) | 76.81 Â± 11.20 | 12,786 | 41.8% |
| ğŸŒ² Random Forest | 73.04 Â± 11.93 | 12,747 | 42.0% |
| ğŸš€ **XGBoost** | **68.23 Â± 9.73** | **9,582** | **56.4%** |

> **Key Insight:** Incorporating NLP features (Bag of Words on product descriptions) provided a significant jump from 5.2% â†’ 41.8% RÂ², demonstrating that textual product information carries substantial pricing signal. XGBoost achieved the best classical ML performance with a 56.4% RÂ² and the tightest confidence interval.

---

## ğŸ”¬ Project Phases

### Phase 1 â€” Data Curation & Preprocessing
- Source the Amazon retail product dataset from Hugging Face
- Exploratory data analysis (EDA) and statistical profiling
- Handle missing values, outliers, and data type inconsistencies
- Feature engineering for numerical and categorical attributes
- Text preprocessing for product descriptions

### Phase 2 â€” Classical ML Baselines & Evaluation
- Establish naive baselines (Random Pricer, Constant Pricer)
- Train and evaluate Linear Regression, NLP-enhanced Linear Regression (Bag of Words), Random Forest, and XGBoost
- Compare models using MAE, MSE, RÂ², and confidence intervals
- Error tracking and systematic performance logging

### Phase 3 â€” Supervised Fine-Tuning (SFT) with Frontier LLMs
- Fine-tune **OpenAI GPT-4o-mini** using LoRA (Low-Rank Adaptation) for price prediction
- Fine-tune **Meta Llama 3.2** for retail domain price estimation
- Prepare JSONL training datasets for SFT workflows
- Evaluate fine-tuned LLMs against classical ML baselines

### Phase 4 â€” Agentic AI Serverless RAG Application
- Build a **multi-modal RAG pipeline** with ChromaDB as the vector store
- Orchestrate agent workflows with **LangChain**
- Deploy an interactive UI with **Gradio**
- Run serverless inference on **Modal.com** for scalable, cost-efficient compute
- Combine fine-tuned models with retrieval-augmented context for intelligent pricing

---

## ğŸ› ï¸ Tech Stack

| Category | Technologies |
|:---------|:-------------|
| **Language** | Python 3.11+ |
| **Notebooks** | Jupyter Notebook |
| **Classical ML** | scikit-learn, XGBoost, NumPy, Pandas |
| **NLP** | Bag of Words (CountVectorizer), text preprocessing |
| **Dataset** | Hugging Face Datasets (Amazon Retail) |
| **LLM Fine-Tuning** | OpenAI API (GPT-4o-mini, LoRA), Meta Llama 3.2 |
| **Vector DB** | ChromaDB |
| **Orchestration** | LangChain |
| **Frontend** | Gradio |
| **Serverless** | Modal.com |
| **Data Format** | JSONL (for SFT training data) |

---

## ğŸ“ Repository Structure

```
ml-retail-price-predictor/
â”œâ”€â”€ data_curation.ipynb          # Data sourcing, EDA, and curation
â”œâ”€â”€ data_preprocessing.ipynb     # Feature engineering and preprocessing
â”œâ”€â”€ evaluation_baseline.ipynb    # Classical ML model training and evaluation
â”œâ”€â”€ error_tracking.txt           # Systematic error and performance logs
â”œâ”€â”€ jsonl/                       # JSONL training data for LLM fine-tuning
â”œâ”€â”€ pricer/                      # Core pricing module and utilities
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## ğŸš€ Getting Started

### Prerequisites

```bash
python >= 3.11
pip install jupyter numpy pandas scikit-learn xgboost
pip install datasets transformers    # Hugging Face
pip install openai                   # OpenAI fine-tuning
pip install langchain chromadb       # RAG pipeline
pip install gradio modal             # App deployment
```

### Run the Notebooks

```bash
# 1. Data Curation & EDA
jupyter notebook data_curation.ipynb

# 2. Preprocessing & Feature Engineering
jupyter notebook data_preprocessing.ipynb

# 3. Model Training & Evaluation
jupyter notebook evaluation_baseline.ipynb
```

---

## ğŸ“ˆ Results Visualization

```
RÂ² Score Progression Across Models
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Random Pricer        â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  -896.9%  â† Worse than random
Constant Pricer      â–Œ                                       -0.2%
Linear Regression    â–ˆâ–ˆâ–Œ                                      5.2%
NLP + Linear Reg.    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                   41.8%
Random Forest        â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                   42.0%
XGBoost              â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ           56.4%  â† Best classical ML

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
                     0%         25%         50%         75%        100%
```

---

## ğŸ”® Roadmap

- [x] Data curation and preprocessing pipeline
- [x] Classical ML baseline evaluation (6 models)
- [ ] OpenAI GPT-4o-mini fine-tuning with LoRA
- [ ] Meta Llama 3.2 fine-tuning
- [ ] ChromaDB vector store integration
- [ ] LangChain agentic workflow orchestration
- [ ] Gradio interactive UI
- [ ] Modal.com serverless deployment
- [ ] Multi-modal RAG application (end-to-end)

---

## ğŸ¤ Contributing

Contributions, issues, and feature requests are welcome. Feel free to open an issue or submit a pull request.

---

## ğŸ“„ License

This project is open source and available under the [MIT License](LICENSE).

---

<p align="center">
  <sub>Built with â˜• and curiosity â€” progressing from classical ML to agentic AI</sub>
</p>